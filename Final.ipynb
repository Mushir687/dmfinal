import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.datasets.samples_generator import make_blobs
dataset = pd.read_csv('LoanDefaultData.csv', delimiter=',')
empty_cols = [i for i in range(30,36)]
dataset = dataset.drop(dataset.columns[empty_cols],axis=1)
#features = ["loan_default","AP001","AP002","AP003","AP004","CR009","CR017","CR018","CR019","PA022","PA023","PA028","PA029","PA030","PA031"]
features = ["loan_default","AP001","AP004","CR009"]
Final_data = dataset[features]
Final_data = Final_data.fillna(0)
Final_data.replace([-98, -99],0)
#print(Final_data.isnull())
# Final_data['AP002'] = Final_data['AP002'].map({1:'Male',2:'Female'})
X = Final_data.iloc[:,1:]
y = Final_data.iloc[:,0]
#print(sns.displot(Final_data['CR009']))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)

from sklearn.tree import DecisionTreeClassifier
logmodel = DecisionTreeClassifier()
logmodel.fit(X_train, y_train)

probs_y=logmodel.predict_proba(X_test)
score = logmodel.score(X_test, y_test)
print("Decision Tree Accuracy:",score)


from sklearn.svm import SVC
gb_model = SVC(kernel='rbf')
gb_model.fit(X_train, y_train)
y_pred=gb_model.predict(X_test)
svm=accuracy_score(y_test, y_pred)
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",svm)

z=['Decision Tree','SVM']
t=[score,svm]
indices=np.arange(2)

import matplotlib.pyplot as plt
plt.title('Accuracy')
plt.barh(range(len(indices)), t, color='b', align='center')
plt.yticks(range(len(indices)), [z[i] for i in indices])
plt.xlabel('Comparison Between Decision tree and SVM')
plt.show()
